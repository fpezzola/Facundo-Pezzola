{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xLYfPmvgAqn7"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOPSF3mG02vTbaKsL/759xg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Wt1ott6YBhJ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EuwJQJxUiwcn"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.colab import data_table\n",
        "from datetime import datetime, timedelta\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import userdata\n",
        "\n",
        "import pandas_gbq\n",
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate & Prepare"
      ],
      "metadata": {
        "id": "4t3o9O1cBWP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Authenticate\n",
        "sa_secret_key = userdata.get('SA_SECRET_KEY')\n",
        "credentials = service_account.Credentials.from_service_account_info(json.loads(sa_secret_key))\n",
        "pandas_gbq.context.credentials = credentials"
      ],
      "metadata": {
        "id": "_wc4QVQqi0t5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'bigtimestudios' # Project ID inserted based on the query results selected to explore\n",
        "location = 'US' # Location inserted based on the query results selected to explore\n",
        "client = bigquery.Client(project=project_id, location=location, credentials=credentials)\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "2ijXQ-NnvHDn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BIG_QUERY_DATASETS AND TABLES\n",
        "DATASET='design_events_views'\n",
        "VIEWS_CONFIG_TABLE='views_config'\n",
        "VIEWS_CONFIG_REF=\"{0}.{1}\".format(DATASET,VIEWS_CONFIG_TABLE)\n",
        "\n",
        "ACK_KEYS_TABLE='design_events_ack_keys'\n",
        "ACK_KEYS_TABLE_REF=\"{0}.{1}\".format(DATASET,ACK_KEYS_TABLE)\n",
        "\n",
        "DESIGN_EVENTS_TABLE_REF = 'game_analytics.design_events'\n"
      ],
      "metadata": {
        "id": "YpcXzS4D6lNS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Daily ACK event keys\n",
        "Build daily keys based on the design_events table"
      ],
      "metadata": {
        "id": "NhuORz1hASk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_keys_query(date):\n",
        "  if date is None:\n",
        "    date = datetime.strftime(datetime.now(), '%Y-%m-%d')\n",
        "  return ('''\n",
        "  CREATE TEMP FUNCTION json_keys(custom_fields STRING)\n",
        "  RETURNS ARRAY<STRING>\n",
        "  LANGUAGE js AS \"\"\"\n",
        "  return Object.keys(JSON.parse(custom_fields))\n",
        "  \"\"\";\n",
        "\n",
        "  with all_keys_per_event_id as (\n",
        "    SELECT event_id, json_keys(custom_fields) fk FROM {0}\n",
        "    WHERE TIMESTAMP_TRUNC(_PARTITIONTIME, DAY) = TIMESTAMP(\"{1}\")\n",
        "    and custom_fields is not null\n",
        "  ),\n",
        "\n",
        "  unnested_and_grouped_event_id_keys as (\n",
        "    SELECT event_id, key FROM all_keys_per_event_id, unnest(fk) key\n",
        "    group by event_id, key\n",
        "  )\n",
        "\n",
        "  SELECT event_id, ARRAY_AGG(key) keys FROM unnested_and_grouped_event_id_keys group by event_id\n",
        "  ''').format(DESIGN_EVENTS_TABLE_REF,date)\n"
      ],
      "metadata": {
        "id": "3Dct02UnTuij"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#UPDATE THE ACK KEYS\n",
        "processing_date = datetime.strftime(datetime.now(), '%Y-%m-%d')\n",
        "\n",
        "def compare_date_str(date_str_1, date_str_2, format= '%Y-%m-%d'):\n",
        "  date_1 = datetime.strptime(date_str_1, format)\n",
        "  date_2 = datetime.strptime(date_str_2, format)\n",
        "  if date_1 == date_2:\n",
        "    return 0\n",
        "  if date_1 > date_2:\n",
        "    return 1\n",
        "  return -1\n",
        "\n",
        "#current_config shape:\n",
        "# \"key\": {last_found_date:\"\"}\n",
        "def merge_with_current_config(current_config,new_keys, date):\n",
        "  new_config = current_config\n",
        "  if new_config is None:\n",
        "    new_config = {}\n",
        "  for key in new_keys:\n",
        "      last_found_date = date\n",
        "      if key in new_config:\n",
        "       if compare_date_str(new_config[key]['last_found_date'],date) > 1:\n",
        "        last_found_date = new_config[key].last_found_date\n",
        "      new_config[key] = {'last_found_date': date }\n",
        "  return new_config\n",
        "\n",
        "#Get data from ack keys table\n",
        "dataset_ref = bigquery.DatasetReference(project_id, DATASET)\n",
        "table_ref = dataset_ref.table(ACK_KEYS_TABLE)\n",
        "table = client.get_table(table_ref)\n",
        "\n",
        "ack_keys_df = client.list_rows(table).to_dataframe()\n",
        "ack_keys_dic = {}\n",
        "#build keys dictionary\n",
        "for index, row in ack_keys_df.iterrows():\n",
        "  event_id = row['event_id']\n",
        "  ##TODO:run keys expiration here\n",
        "  ack_keys_dic[event_id] = json.loads(row['keys'])\n",
        "\n",
        "keys_query = generate_keys_query(processing_date)\n",
        "today_ack_keys_df = client.query(keys_query).to_dataframe().reset_index()\n",
        "\n",
        "for index, row in today_ack_keys_df.iterrows():\n",
        "  event_id = row['event_id']\n",
        "  current_config = {}\n",
        "  if event_id in ack_keys_dic:\n",
        "    current_config = ack_keys_dic[event_id]\n",
        "  ack_keys_dic[event_id] = merge_with_current_config(current_config,row['keys'],processing_date)\n",
        "\n",
        "dict_for_data_frame = {\n",
        "    'event_id':[],\n",
        "    'keys':[]\n",
        "}\n",
        "\n",
        "for k, v in ack_keys_dic.items():\n",
        "  dict_for_data_frame['event_id'].append(k)\n",
        "  dict_for_data_frame['keys'].append(json.dumps(v))\n",
        "\n",
        "df = pd.DataFrame.from_dict(dict_for_data_frame)\n",
        "\n",
        "df.to_gbq(ACK_KEYS_TABLE_REF, project_id=project_id,if_exists='replace')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vFlOYFBocfo",
        "outputId": "7e8439f1-33ac-48ea-fd34-c1f6b5a3457e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 988.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Views creation"
      ],
      "metadata": {
        "id": "xLYfPmvgAqn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IDS_CONCAT_TOKEN = ':'\n",
        "\n",
        "#concat ids helpers\n",
        "def concat_ids(base_id,candidates):\n",
        "  for candidate in candidates:\n",
        "    if candidate == '*':\n",
        "      return base_id\n",
        "    else:\n",
        "      base_id = base_id + IDS_CONCAT_TOKEN + candidate\n",
        "  return base_id"
      ],
      "metadata": {
        "id": "krctb3992x68"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE AND GET VIEWS HELPERS\n",
        "\n",
        "def get_view_name(specified,id):\n",
        "  if specified is None:\n",
        "    return 'design_events_' + id.replace(':','_')\n",
        "  return specified\n",
        "\n",
        "def build_view_query(keys_to_extract,event_id_like):\n",
        "  properties = ['* EXCEPT(custom_fields)']\n",
        "  for k in keys_to_extract:\n",
        "    properties.append(\"JSON_EXTRACT(custom_fields,'$.{0}') as {1}\".format(k,k))\n",
        "  return 'SELECT {0} FROM {1} WHERE event_id like \"{2}%\";'.format(\", \".join(properties),DESIGN_EVENTS_TABLE_REF,event_id_like)\n",
        "\n",
        "def create_view(client, dataset_name, view_name, view_query, exists_replace=True):\n",
        "    try:\n",
        "        dataset_ref = client.dataset(dataset_name)\n",
        "        view_ref = dataset_ref.table(view_name)\n",
        "        if exists_replace:\n",
        "          client.delete_table(table=view_ref,not_found_ok=True)\n",
        "        table = bigquery.Table(view_ref)\n",
        "        table.view_query = view_query\n",
        "        table.view_use_legacy_sql = False\n",
        "        client.create_table(table,exists_ok=True)\n",
        "    except Exception as e:\n",
        "        errorStr = 'ERROR (create_view): ' + str(e)\n",
        "        print(errorStr)\n",
        "        raise"
      ],
      "metadata": {
        "id": "Iy8nL_aB0JdR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN VIEWS CREATION\n",
        "sql_query = ('''SELECT * FROM {0};''')\n",
        "\n",
        "df_views_config = client.query(sql_query.format(VIEWS_CONFIG_REF)).to_dataframe().reset_index()  # make sure indexes pair with number of rows\n",
        "\n",
        "event_ids = {}\n",
        "for index, row in df_views_config.iterrows():\n",
        "  event_id_01 = row['event_id_01']\n",
        "  if event_id_01 == '*':\n",
        "    print('Wrong config: * is not allowed in the event_id_01 field')\n",
        "    print('Discarding view creation...')\n",
        "    continue\n",
        "  id = concat_ids(event_id_01,[row['event_id_02'],row['event_id_03'],row['event_id_04'],row['event_id_05']])\n",
        "  event_ids[id] = get_view_name(row['destination_view_name'],id)\n",
        "\n",
        "for event_id, view_name in event_ids.items():\n",
        "    get_ack_keys_query = ('''SELECT * FROM {0} WHERE event_id like \"{1}%\"''')\n",
        "    ack_df = client.query(get_ack_keys_query.format(ACK_KEYS_TABLE_REF,event_id)).to_dataframe().reset_index()\n",
        "    keys_set = set()\n",
        "    for index,row in ack_df.iterrows():\n",
        "      ack_keys = json.loads(\"{0}\".format(row['keys']));\n",
        "      print(event_id)\n",
        "      print(ack_keys)\n",
        "      for k,v in ack_keys.items():\n",
        "        keys_set.add(k)\n",
        "    create_view(client, DATASET, view_name, build_view_query(keys_set,event_id), exists_replace=True)"
      ],
      "metadata": {
        "id": "bpOyfVGEi6Lb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}